

# Xpath 

- 安装及使用


    pip install lxml  /  pycharm安装
    from lxml import etree


- 专门针对HTML解析提取数据
- XPath 使用路径表达式来选取HTML文档中的节点, 类似电脑文件系统中看到的表达式非常相似
- 插件工具


    谷歌: XPath Helper
    火狐: https://addons.mozilla.org/zh-CN/firefox/search/?platform=windows&q=xpath



--------------------------------------------


## XPATH 术语

#### 节点（Node）

在 XPath 中，有七种类型的节点：元素、属性、文本、命名空间、处理指令、注释以及文档（根）节点



    <html>
        <head>
          <title lang="en">Harry Potter</title>
        </head>
        <body>
            <div>
                <div>J K. Rowling</div> 
                    <span>2005</span>
                <div>29.99</div>
            </div>
            <div>
                <div>J K. Rowling</div> 
                    <span>2005</span>
                <div>29.99</div>
            </div>
        </body>
    </html>

------------------------------



#### 节点关系
- 父（Parent） 每个元素以及属性都有一个父
- 子（Children）  元素节点可有零个、一个或多个子
在下面的例子中，title、author、year 以及 price 元素都是 book 元素的子
- 先辈（Ancestor）   某节点的父、父的父，等等
- 后代（Descendant）  某个节点的子，子的子，等等。 
- 同胞（Sibling）  拥有相同的父的节点




## 选取节点

XPath 使用路径表达式在 HTML 文档中选取节点

#### 表达式


    result = res_html.xpath('/html/body/div/div')
    result = res_html.xpath('/html/body/div[1]')
    result = res_html.xpath('/html/body/div[1]/div[2]/text()')
    result = res_html.xpath('/html/body/div[1]/div[]/text()')
    result = res_html.xpath('/html')[0]
    result = res_html.xpath('/html/head/title/text()')[0]
    result = res_html.xpath('/html/head/title/@lang')[0]
    result = res_html.xpath('/html//title/text()')[0]


### 注意

- 列表索引从0开始, xpath索引从1开始
               
--------------------------------------------------


#### 1. 校花网获取校花个人信息及相册图片


    import requests
    from lxml import etree
    from time import time, sleep
    import os


​    
    class MeiZiPic(object):
    
        def __init__(self):
            self.headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.109 Safari/537.36'
            }
    
        def get_list_url(self, url):
            print('开始请求分页:{}'.format(url))
            sleep(3)
            resp = requests.get(url, headers=self.headers)
            with open('校花.html','w')as f:
                f.write(resp.text)
            resp_html = etree.HTML(resp.text)
            url_list = resp_html.xpath('//div[@class="item_list infinite_scroll"]//div[@class="item_t"]//div[@class="img"]/a/@href')
            print(url_list)
            return url_list
    
        def get_detail_page(self, detail_page_url):
            sleep(6)
            print('正在解析详情页:{}.....'.format(detail_page_url))
            func = lambda x:x[0] if x else ''
    
            resp = requests.get(detail_page_url, headers=self.headers)
            resp_html = etree.HTML(resp.text)
            result = {}
            result['name'] = func(resp_html.xpath('//div[@class="infodiv"]//tr[1]/td[2]/text()'))
            result['xingzuo'] = func(resp_html.xpath('//div[@class="infodiv"]//tr[3]/td[2]/text()'))
            result['major'] = func(resp_html.xpath('//div[@class="infodiv"]//tr[4]/td[2]/text()'))
            result['school'] = func(resp_html.xpath('//div[@class="infodiv"]//tr[5]/td[2]/text()'))
            result['job'] = func(resp_html.xpath('//div[@class="infodiv"]//tr[6]/td[2]/text()'))
            result['score'] = func(resp_html.xpath('//div[@class="infodiv"]//div[@class="score_div"]/span[@id="span_score"]/text()'))
            result['pic_list'] = resp_html.xpath('//div[@id="post"]//div[@class="entry_box"][3]//div[@class="post_entry"]/ul/li//img/@src')
            return  result
    
        def write_page(self, result_dict):
            with open('校花信息.json', 'a', encoding='utf-8') as f:
                f.write(str(result_dict)+'\n')
                print('{}_写入完毕....'.format(result_dict['name']))
    
        def get_pic(self, pic_list, name):
            if not os.path.exists('./校花相册/{}'.format(name)):
                os.mkdir('./校花相册/{}'.format(name))
    
            for i in pic_list:
                if not i.startswith('http'):
                    continue
                resp = requests.get(i, self.headers)
                with open('./校花相册/{}/{}.jpg'.format(name, time()),'wb')as f:
                    f.write(resp.content)
            print('{}_的照片, {}张下载完毕...'.format(name, len(pic_list)))
    
    if __name__ == '__main__':
        meizi = MeiZiPic()
    
        for i in range(10):
            index_url = 'http://www.xiaohuar.com/list-1-{}.html'.format(i)
            detail_url_list = meizi.get_list_url(index_url)
            for i in detail_url_list:
                result_sict = meizi.get_detail_page(i)
                meizi.write_page(result_sict)
                meizi.get_pic(result_sict['pic_list'], result_sict['name'])
                break
            break



#### 2. 豆瓣音乐


    import requests
    from lxml import etree
    from time import time, sleep
    import re


​    
    class Douban(object):
        def __init__(self):
            self.headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.109 Safari/537.36'
            }
    
        def get_style_url_list(self, url):
            sleep(3)
            resp = requests.get(url, headers=self.headers)
            resp_html = etree.HTML(resp.text)
            a_list = resp_html.xpath('//div[@id="content"]//div[@class="indent"]/span/a/@href')
            return a_list
    
        def get_every_style_url_list(self, url):
            sleep(3)
            resp = requests.get(url, headers=self.headers)
            resp_html = etree.HTML(resp.text)
            detail_page_url = resp_html.xpath('//div[@id="wrapper"]//div[@class="article"]/div[@class="site_bar"]/a/@href')
            return detail_page_url
    
        def get_and_parse_detail_page(self, url):
            func = lambda x: x[0] if x else ''
            result_dict = {}
            resp = requests.get(url, headers=self.headers)
            resp_html = etree.HTML(resp.text)
            result_dict['name'] = func(resp_html.xpath('//div[@id="header"]//div[@class="sp-logo"]//a/text()'))
            # 图片链接
            result_dict['pic_src'] = func(resp_html.xpath('//div[@class="aside"]//div[@class="user-pic"]/img/@src'))
            # 首页介绍
            result_dict['content'] = re.sub('\s+', '', ''.join(resp_html.xpath('//div[@id="content"]//div[@class="main"]//div[@class="mod"]//div[@class="bulletin-content"]/text()')))
            return result_dict
    
        def get_pic(self, pic_src, name):
            resp = requests.get(pic_src, self.headers)
            with open('./pic/{}.jpg'.format(name), 'wb')as f:
                f.write(resp.content)
                print('图片:{}_下载完毕.......'.format(name))
    
        def write_page(self, result_dict):
            with open('douban_music.json','a',encoding='utf-8')as f:
                f.write(str(result_dict)+'\n')
                print('已经写入:{}.......'.format(result_dict['name']))


​    
    if __name__ == '__main__':
        url = 'https://music.douban.com/artists/tag/?start=0'
    
        music = Douban()
        # 所有类别分页只要前5页
        for style_page in range(0, 1000, 200):
            url = 'https://music.douban.com/artists/tag/?start={}'.format(style_page)
            style_url_list = music.get_style_url_list(url)
            # 200个类别只要第一个类别
            for i in style_url_list[:1]:
                # 每个类别取5页
                for num in range(2,5):
                    i = 'https://music.douban.com/artists/tag/%E6%B5%81%E8%A1%8C?page={}'.format(num)
                    every_style_url_list = music.get_every_style_url_list(i)
                    # 每页解析10条
                    for j in every_style_url_list:
                        result_dict = music.get_and_parse_detail_page(j)
                        music.write_page(result_dict)
                        music.get_pic(result_dict['pic_src'], result_dict['name'])
                    break
            break







​    


