
# CSS选择器

- 使用BeautifulSoup提供的CSS选择器, 来解析HTML


## 使用和安装


    
    pip install Beautifulsoup4 / pycharm安装
    
    from bs4 import BeautifulSoup


## 选择器
- 类选择器
- id选择器
- 标签选择器

参考链接:
    http://www.w3school.com.cn/cssref/css_selectors.asp
    
    指定lxml解析器,构造soup对象
    
    a = """
    <html>
        <head>
          <title lang="en">Harry Potter</title>
        </head>
        <body>
            <div>
                <div id='a'>J K. Rowling
                    <span>2005</span>
                </div> 
                <div>29.99</div>
            </div>
            <div class='div2'>
                <div class="div3">J K. Rowling</div> 
                    <span id='span'>2005</span>
                <div>29.99</div>
            </div>
        </body>
    </html>
    """
    soup = BeautifulSoup(a, 'lxml')
    
    # > 直接儿子
    res = soup.select('head > title')[0].text
    res = soup.select('div#a > span')[0].text
    
    # 空格: 间接儿子
    res = soup.select('body div#a')[0].text
    res = soup.select('div#a span')[0].text
    
    # 属性查找
    res= soup.select('title[lang=en]')[0].text
    res= soup.select('title[lang]')[0].attrs['lang']
    print(res)
 
 
    
#### 注意
    select 方法返回的结果是列表形式，通过索引取值，之后用 get_text()方法来获取标签内的文本, 或者使用.text获取标签内的文本

--------------------------------------------------------


## 以下内容作为了解（感兴趣的同学可以自学） ➡️

## BeautifulSoup 
#### 1. 创建 beautifulsoup 对象

            soup = BeautifulSoup(html,'lxml')  

#### 2. 使用 
- prettify()  格式化输出DOM 树


        html = """<!DOCTYPE html>
        <html>
        <head>
        	<title>我们</title>
        </head>
        <body>
            <div id='id'>
        		nihao w dhweufbd
        		<div>
        			<span id='ni'><a href="" class="abiaoqian">sdjweihfw</a></span>
        		</div>
        	</div>
        	<div>
        		<img src="#">dhwefiu
        	</div>
        	
        	<a href="#">efuwehihcfwe</a>
        	<p class='ppp'>ppppp</p>		
        	<p id='wp'>niha</p>
        	<p id='p'>djcnsiuw</p>
        </body>
        </html>"""

- 节点内容


    print soup.title
    print soup.head
    print soup.a
    print soup.p
    print soup.a.name
    print soup.p.attrs #p标签的所有属性, 得到的类型是一个字典
    
    print type(soup.a)    
    print type(soup)       
    print soup.name        

    print (soup.p.string)
    print (type(soup.p.string))    
    print(soup.strings)    
    print(soup.stripped_strings)    #去空行
        
        
- 取父级标签名


    print (soup.span.parent.name)
    print (soup.a.parent.name)
    print (soup.p.parents)           


- 获取兄弟节点

        
    .next_sibling 属性获取了该节点的下一个兄弟节点
    .previous_sibling 属性获取了该节点的上一个兄弟节点，如果节点不存在，则返回 None
    
    注意：实际文档中的tag的 .next_sibling 和 .previous_sibling 属性通常是字符串或空白，因为空白或者换行也可以被视作一个节点，所以得到的结果可能是空白或者换行

- 直接子节点


    print (soup.div.contents)     
    print (soup.head.contents)      
    print (soup.div.children)    
        
- 遍历所有子节点


        soup.div.descendants            
        
- find_all搜索文档树
        

    print (soup.find_all('p'))
    print (soup.find_all(["a", "img"]))
    print (soup.find_all(id='id'))
    print (soup.find_all(href=re.compile("elsie")))
        
 
###  [文档地址](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)


